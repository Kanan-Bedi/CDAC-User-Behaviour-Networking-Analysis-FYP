{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9796046,"sourceType":"datasetVersion","datasetId":6003316}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:51:00.595836Z","iopub.execute_input":"2024-11-03T16:51:00.596177Z","iopub.status.idle":"2024-11-03T16:51:01.669090Z","shell.execute_reply.started":"2024-11-03T16:51:00.596126Z","shell.execute_reply":"2024-11-03T16:51:01.668135Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/final-csv/final_4.2.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:51:07.795021Z","iopub.execute_input":"2024-11-03T16:51:07.795998Z","iopub.status.idle":"2024-11-03T16:51:20.516280Z","shell.execute_reply.started":"2024-11-03T16:51:07.795958Z","shell.execute_reply":"2024-11-03T16:51:20.515289Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load your dataset\ndata = pd.read_csv('/kaggle/input/final-csv/final_4.2.csv') ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:51:22.979062Z","iopub.execute_input":"2024-11-03T16:51:22.980108Z","iopub.status.idle":"2024-11-03T16:51:28.737945Z","shell.execute_reply.started":"2024-11-03T16:51:22.980065Z","shell.execute_reply":"2024-11-03T16:51:28.736950Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Parse 'action_id' and 'day_minutes' as sequences\ndef safe_eval_string_to_list(s):\n    try:\n        return list(map(int, s.strip('[]').split()))  # Adjust based on actual data format\n    except Exception as e:\n        print(f\"Error parsing {s}: {e}\")\n        return []\n\ndata['action_id_seq'] = data['action_id'].apply(safe_eval_string_to_list)\ndata['day_minutes_seq'] = data['day_minutes'].apply(safe_eval_string_to_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:51:28.739507Z","iopub.execute_input":"2024-11-03T16:51:28.739822Z","iopub.status.idle":"2024-11-03T16:51:43.644326Z","shell.execute_reply.started":"2024-11-03T16:51:28.739789Z","shell.execute_reply":"2024-11-03T16:51:43.643299Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Scale and pad sequences for uniform length\nscaler = MinMaxScaler()\naction_id_scaled = scaler.fit_transform(pad_sequences(data['action_id_seq'], padding='post', dtype='float32'))\nday_minutes_scaled = scaler.fit_transform(pad_sequences(data['day_minutes_seq'], padding='post', dtype='float32'))\n\n# Combine action_id and day_minutes as separate features in the sequence data\nX_sequences = np.stack((action_id_scaled, day_minutes_scaled), axis=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:51:45.711013Z","iopub.execute_input":"2024-11-03T16:51:45.711746Z","iopub.status.idle":"2024-11-03T16:52:04.245966Z","shell.execute_reply.started":"2024-11-03T16:51:45.711708Z","shell.execute_reply":"2024-11-03T16:52:04.245165Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Define the LSTM + CNN autoencoder model\ninput_shape = X_sequences.shape[1:]\ninput_layer = Input(shape=input_shape)\nx = Conv1D(64, kernel_size=3, activation='relu')(input_layer)\nx = MaxPooling1D(pool_size=2)(x)\nx = LSTM(50, return_sequences=True)(x)\nx = Flatten()(x)\nx = Dense(50, activation='relu')(x)\noutput_layer = Dense(input_shape[0] * input_shape[1], activation='sigmoid')(x)  # Flattened output\n\nautoencoder = Model(inputs=input_layer, outputs=output_layer)\nautoencoder.compile(optimizer=Adam(learning_rate=1e-4), loss='mse')\nautoencoder.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:52:10.156890Z","iopub.execute_input":"2024-11-03T16:52:10.157807Z","iopub.status.idle":"2024-11-03T16:52:11.508639Z","shell.execute_reply.started":"2024-11-03T16:52:10.157753Z","shell.execute_reply":"2024-11-03T16:52:11.507804Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m174\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m172\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m448\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m23,000\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4300\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │       \u001b[38;5;34m215,050\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m348\u001b[0m)            │        \u001b[38;5;34m17,748\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">174</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">172</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,000</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4300</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">215,050</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">348</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,748</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m256,246\u001b[0m (1000.96 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256,246</span> (1000.96 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m256,246\u001b[0m (1000.96 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256,246</span> (1000.96 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Reshape output for training\nX_train = X_sequences.reshape((X_sequences.shape[0], -1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:52:19.744914Z","iopub.execute_input":"2024-11-03T16:52:19.745629Z","iopub.status.idle":"2024-11-03T16:52:19.749826Z","shell.execute_reply.started":"2024-11-03T16:52:19.745590Z","shell.execute_reply":"2024-11-03T16:52:19.748858Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\n\n# Define the ModelCheckpoint callback to save the model during training\ncheckpoint_callback = ModelCheckpoint(\n    'lstm_cnn_autoencoder_best.keras',  # Save with .keras extension\n    monitor='val_loss',                 # Monitor validation loss\n    save_best_only=True,                # Only save when validation loss improves\n    mode='min',                         # Save when the loss is minimized\n    verbose=1\n)\n\n# Train the model with the checkpoint callback\nhistory = autoencoder.fit(\n    X_sequences, X_train, \n    epochs=50, \n    batch_size=32, \n    validation_split=0.2, \n    verbose=1, \n    callbacks=[checkpoint_callback]  # Include the callback here\n)\n\nprint(\"Model training complete. The best model is saved as 'lstm_cnn_autoencoder_best.keras'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T16:54:20.265861Z","iopub.execute_input":"2024-11-03T16:54:20.266399Z","iopub.status.idle":"2024-11-03T20:12:01.067585Z","shell.execute_reply.started":"2024-11-03T16:54:20.266347Z","shell.execute_reply":"2024-11-03T20:12:01.066528Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0114\nEpoch 1: val_loss improved from inf to 0.00084, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 7ms/step - loss: 0.0114 - val_loss: 8.4133e-04\nEpoch 2/50\n\u001b[1m34843/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0783e-04\nEpoch 2: val_loss improved from 0.00084 to 0.00051, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 7.0781e-04 - val_loss: 5.0778e-04\nEpoch 3/50\n\u001b[1m34845/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6543e-04\nEpoch 3: val_loss improved from 0.00051 to 0.00040, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 4.6543e-04 - val_loss: 3.9597e-04\nEpoch 4/50\n\u001b[1m34844/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8454e-04\nEpoch 4: val_loss improved from 0.00040 to 0.00036, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 3.8453e-04 - val_loss: 3.5765e-04\nEpoch 5/50\n\u001b[1m34844/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3466e-04\nEpoch 5: val_loss improved from 0.00036 to 0.00031, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 7ms/step - loss: 3.3466e-04 - val_loss: 3.0915e-04\nEpoch 6/50\n\u001b[1m34845/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0015e-04\nEpoch 6: val_loss did not improve from 0.00031\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 3.0014e-04 - val_loss: 3.1798e-04\nEpoch 7/50\n\u001b[1m34845/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7736e-04\nEpoch 7: val_loss improved from 0.00031 to 0.00026, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 2.7736e-04 - val_loss: 2.6108e-04\nEpoch 8/50\n\u001b[1m34850/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5679e-04\nEpoch 8: val_loss improved from 0.00026 to 0.00025, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 2.5679e-04 - val_loss: 2.4738e-04\nEpoch 9/50\n\u001b[1m34846/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4218e-04\nEpoch 9: val_loss improved from 0.00025 to 0.00024, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 2.4218e-04 - val_loss: 2.3935e-04\nEpoch 10/50\n\u001b[1m34847/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3372e-04\nEpoch 10: val_loss improved from 0.00024 to 0.00023, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 7ms/step - loss: 2.3372e-04 - val_loss: 2.2804e-04\nEpoch 11/50\n\u001b[1m34848/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9022e-04\nEpoch 11: val_loss did not improve from 0.00023\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 7ms/step - loss: 2.9021e-04 - val_loss: 2.4035e-04\nEpoch 12/50\n\u001b[1m34844/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3034e-04\nEpoch 12: val_loss improved from 0.00023 to 0.00022, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 7ms/step - loss: 2.3034e-04 - val_loss: 2.2067e-04\nEpoch 13/50\n\u001b[1m34849/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1833e-04\nEpoch 13: val_loss improved from 0.00022 to 0.00021, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 7ms/step - loss: 2.1833e-04 - val_loss: 2.0958e-04\nEpoch 14/50\n\u001b[1m34849/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0976e-04\nEpoch 14: val_loss improved from 0.00021 to 0.00020, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 7ms/step - loss: 2.0976e-04 - val_loss: 2.0253e-04\nEpoch 15/50\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0215e-04\nEpoch 15: val_loss improved from 0.00020 to 0.00020, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 2.0215e-04 - val_loss: 1.9880e-04\nEpoch 16/50\n\u001b[1m34846/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9508e-04\nEpoch 16: val_loss did not improve from 0.00020\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7ms/step - loss: 1.9508e-04 - val_loss: 2.0120e-04\nEpoch 17/50\n\u001b[1m34846/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9039e-04\nEpoch 17: val_loss improved from 0.00020 to 0.00019, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.9039e-04 - val_loss: 1.9319e-04\nEpoch 18/50\n\u001b[1m34849/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8576e-04\nEpoch 18: val_loss improved from 0.00019 to 0.00019, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.8576e-04 - val_loss: 1.8659e-04\nEpoch 19/50\n\u001b[1m34846/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8128e-04\nEpoch 19: val_loss improved from 0.00019 to 0.00018, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.8128e-04 - val_loss: 1.7887e-04\nEpoch 20/50\n\u001b[1m34847/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7713e-04\nEpoch 20: val_loss improved from 0.00018 to 0.00017, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.7713e-04 - val_loss: 1.7413e-04\nEpoch 21/50\n\u001b[1m34846/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7341e-04\nEpoch 21: val_loss did not improve from 0.00017\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 1.7341e-04 - val_loss: 1.7500e-04\nEpoch 22/50\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7113e-04\nEpoch 22: val_loss improved from 0.00017 to 0.00017, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7ms/step - loss: 1.7113e-04 - val_loss: 1.6879e-04\nEpoch 23/50\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6670e-04\nEpoch 23: val_loss did not improve from 0.00017\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.6670e-04 - val_loss: 1.7114e-04\nEpoch 24/50\n\u001b[1m34850/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6479e-04\nEpoch 24: val_loss improved from 0.00017 to 0.00016, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 1.6479e-04 - val_loss: 1.6494e-04\nEpoch 25/50\n\u001b[1m34847/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6245e-04\nEpoch 25: val_loss did not improve from 0.00016\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7ms/step - loss: 1.6245e-04 - val_loss: 1.6535e-04\nEpoch 26/50\n\u001b[1m34848/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6075e-04\nEpoch 26: val_loss improved from 0.00016 to 0.00016, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.6075e-04 - val_loss: 1.6056e-04\nEpoch 27/50\n\u001b[1m34846/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5756e-04\nEpoch 27: val_loss improved from 0.00016 to 0.00016, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 1.5756e-04 - val_loss: 1.5870e-04\nEpoch 28/50\n\u001b[1m34847/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5575e-04\nEpoch 28: val_loss improved from 0.00016 to 0.00016, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.5575e-04 - val_loss: 1.5803e-04\nEpoch 29/50\n\u001b[1m34844/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5177e-04\nEpoch 29: val_loss improved from 0.00016 to 0.00015, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 7ms/step - loss: 1.5177e-04 - val_loss: 1.4883e-04\nEpoch 30/50\n\u001b[1m34843/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4847e-04\nEpoch 30: val_loss did not improve from 0.00015\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 7ms/step - loss: 1.4847e-04 - val_loss: 1.5520e-04\nEpoch 31/50\n\u001b[1m34847/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4498e-04\nEpoch 31: val_loss improved from 0.00015 to 0.00014, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.4498e-04 - val_loss: 1.4123e-04\nEpoch 32/50\n\u001b[1m34846/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4093e-04\nEpoch 32: val_loss improved from 0.00014 to 0.00014, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 1.4093e-04 - val_loss: 1.4068e-04\nEpoch 33/50\n\u001b[1m34847/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3868e-04\nEpoch 33: val_loss did not improve from 0.00014\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.3868e-04 - val_loss: 1.4154e-04\nEpoch 34/50\n\u001b[1m34844/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3663e-04\nEpoch 34: val_loss improved from 0.00014 to 0.00014, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7ms/step - loss: 1.3663e-04 - val_loss: 1.3595e-04\nEpoch 35/50\n\u001b[1m34850/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3424e-04\nEpoch 35: val_loss improved from 0.00014 to 0.00013, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.3424e-04 - val_loss: 1.3418e-04\nEpoch 36/50\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3341e-04\nEpoch 36: val_loss did not improve from 0.00013\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 1.3341e-04 - val_loss: 1.3550e-04\nEpoch 37/50\n\u001b[1m34848/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3156e-04\nEpoch 37: val_loss improved from 0.00013 to 0.00013, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.3156e-04 - val_loss: 1.2976e-04\nEpoch 38/50\n\u001b[1m34843/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2965e-04\nEpoch 38: val_loss improved from 0.00013 to 0.00013, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.2965e-04 - val_loss: 1.2828e-04\nEpoch 39/50\n\u001b[1m34849/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2848e-04\nEpoch 39: val_loss did not improve from 0.00013\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.2848e-04 - val_loss: 1.3422e-04\nEpoch 40/50\n\u001b[1m34846/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2784e-04\nEpoch 40: val_loss did not improve from 0.00013\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7ms/step - loss: 1.2784e-04 - val_loss: 1.2941e-04\nEpoch 41/50\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2673e-04\nEpoch 41: val_loss did not improve from 0.00013\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.2673e-04 - val_loss: 1.3105e-04\nEpoch 42/50\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2494e-04\nEpoch 42: val_loss did not improve from 0.00013\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7ms/step - loss: 1.2494e-04 - val_loss: 1.3094e-04\nEpoch 43/50\n\u001b[1m34849/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2354e-04\nEpoch 43: val_loss improved from 0.00013 to 0.00013, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7ms/step - loss: 1.2354e-04 - val_loss: 1.2714e-04\nEpoch 44/50\n\u001b[1m34849/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2283e-04\nEpoch 44: val_loss did not improve from 0.00013\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.2283e-04 - val_loss: 1.2776e-04\nEpoch 45/50\n\u001b[1m34843/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2236e-04\nEpoch 45: val_loss improved from 0.00013 to 0.00012, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.2236e-04 - val_loss: 1.2251e-04\nEpoch 46/50\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2161e-04\nEpoch 46: val_loss did not improve from 0.00012\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 1.2161e-04 - val_loss: 1.2261e-04\nEpoch 47/50\n\u001b[1m34843/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2069e-04\nEpoch 47: val_loss did not improve from 0.00012\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 1.2069e-04 - val_loss: 1.2388e-04\nEpoch 48/50\n\u001b[1m34849/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2008e-04\nEpoch 48: val_loss improved from 0.00012 to 0.00012, saving model to lstm_cnn_autoencoder_best.keras\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7ms/step - loss: 1.2008e-04 - val_loss: 1.1944e-04\nEpoch 49/50\n\u001b[1m34844/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1884e-04\nEpoch 49: val_loss did not improve from 0.00012\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 1.1884e-04 - val_loss: 1.2121e-04\nEpoch 50/50\n\u001b[1m34850/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1810e-04\nEpoch 50: val_loss did not improve from 0.00012\n\u001b[1m34851/34851\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 7ms/step - loss: 1.1810e-04 - val_loss: 1.2097e-04\nModel training complete. The best model is saved as 'lstm_cnn_autoencoder_best.keras'\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}